{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKYnR/ZjwuS/7qNyn12JxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolekwli/final-year-project/blob/main/notebooks/fyp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Des3O7T-sqCT",
        "outputId": "7289379c-4de1-4f60-c9f5-ed5cebbc3945"
      },
      "source": [
        "# !mkdir datasets\n",
        "# %cd datasets\n",
        "# !wget http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
        "# !tar -xzf train-clean-100.tar.gz || exit\n",
        "# !mkdir LibriSpeech100_labels_split\n",
        "# %cd LibriSpeech100_labels_split || exit\n",
        "# !gdown --id 1vSHmncPsRY7VWWAd_BtoWs9-fQ5cBrEB\n",
        "# !gdown --id 1ubREoLQu47_ZDn39YWv1wvVPe2ZlIZAb\n",
        "# !gdown --id 1bLuDkapGBERG_VYPS7fNZl5GXsQ9z3p2\n",
        "# !unzip converted_aligned_phones.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘datasets’: File exists\n",
            "[Errno 2] No such file or directory: 'datasets || exit'\n",
            "/content\n",
            "--2021-02-14 18:08:30--  http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘train-clean-100.tar.gz.2’\n",
            "\n",
            "train-clean-100.tar 100%[===================>]   5.95G  19.6MB/s    in 5m 18s  \n",
            "\n",
            "2021-02-14 18:13:48 (19.2 MB/s) - ‘train-clean-100.tar.gz.2’ saved [6387309499/6387309499]\n",
            "\n",
            "mkdir: cannot create directory ‘LibriSpeech100_labels_split’: File exists\n",
            "[Errno 2] No such file or directory: 'LibriSpeech100_labels_split || exit'\n",
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vSHmncPsRY7VWWAd_BtoWs9-fQ5cBrEB\n",
            "To: /content/test_split.txt\n",
            "100% 92.6k/92.6k [00:00<00:00, 27.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ubREoLQu47_ZDn39YWv1wvVPe2ZlIZAb\n",
            "To: /content/train_split.txt\n",
            "100% 370k/370k [00:00<00:00, 22.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bLuDkapGBERG_VYPS7fNZl5GXsQ9z3p2\n",
            "To: /content/converted_aligned_phones.zip\n",
            "7.04MB [00:00, 108MB/s]\n",
            "Archive:  converted_aligned_phones.zip\n",
            "replace converted_aligned_phones.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: converted_aligned_phones.txt  \n",
            "replace __MACOSX/._converted_aligned_phones.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._converted_aligned_phones.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fTm-Q5jxe7o",
        "outputId": "3f25d1a9-79e4-44d3-c7c2-3f3d7a6deb35"
      },
      "source": [
        "!wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-14 18:41:18--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2021-02-14 18:41:18--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-4.5.4-Li 100%[===================>]  55.76M   129MB/s    in 0.4s    \n",
            "\n",
            "2021-02-14 18:41:18 (129 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "unlinking: ca-certificates-2017.08.26-h1d4fec5_0\n",
            "unlinking: certifi-2018.1.18-py36_0\n",
            "unlinking: cffi-1.11.4-py36h9745a5d_0\n",
            "unlinking: conda-4.4.10-py36_0\n",
            "unlinking: cryptography-2.1.4-py36hd09be54_0\n",
            "unlinking: libedit-3.1-heed3624_0\n",
            "unlinking: libgcc-ng-7.2.0-h7cc24e2_2\n",
            "unlinking: libstdcxx-ng-7.2.0-h7a57d05_2\n",
            "unlinking: ncurses-6.0-h9df7e31_2\n",
            "unlinking: openssl-1.0.2n-hb7f436b_0\n",
            "unlinking: pip-9.0.1-py36h6c6f9ce_4\n",
            "unlinking: pyopenssl-17.5.0-py36h20ba746_0\n",
            "unlinking: pysocks-1.6.7-py36hd97a5b1_1\n",
            "unlinking: python-3.6.4-hc3d631a_1\n",
            "unlinking: ruamel_yaml-0.15.35-py36h14c3975_1\n",
            "unlinking: setuptools-38.4.0-py36_0\n",
            "unlinking: sqlite-3.22.0-h1bed415_0\n",
            "unlinking: wheel-0.30.0-py36hfd4bba0_1\n",
            "unlinking: xz-5.2.3-h55aa19d_2\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S31yExtu2L8G",
        "outputId": "969d0d16-a081-4f4f-c7ed-3a4460a1dddd"
      },
      "source": [
        "!bash setup_dependencies.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Make sure conda is installed.\n",
            "Installing environment:\n",
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/infomax\n",
            "\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "If your shell is Bash or a Bourne variant, enable conda for the current user with\n",
            "\n",
            "    $ echo \". /usr/local/etc/profile.d/conda.sh\" >> ~/.bashrc\n",
            "\n",
            "or, for all users, enable conda with\n",
            "\n",
            "    $ sudo ln -s /usr/local/etc/profile.d/conda.sh /etc/profile.d/conda.sh\n",
            "\n",
            "The options above will permanently enable the 'conda' command, but they do NOT\n",
            "put conda's base (root) environment on PATH.  To do so, run\n",
            "\n",
            "    $ conda activate\n",
            "\n",
            "in your terminal, or to put the base environment on PATH permanently, run\n",
            "\n",
            "    $ echo \"conda activate\" >> ~/.bashrc\n",
            "\n",
            "Previous to conda 4.4, the recommended way to activate conda was to modify PATH in\n",
            "your ~/.bashrc file.  You should manually remove the line that looks like\n",
            "\n",
            "    export PATH=\"/usr/local/bin:$PATH\"\n",
            "\n",
            "^^^ The above line should NO LONGER be in your ~/.bashrc file! ^^^\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQi8eIzb2YY"
      },
      "source": [
        "!echo \". /usr/local/etc/profile.d/conda.sh\" >> ~/.bashrc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qPjqEaYz4Pj"
      },
      "source": [
        "!source activate infomax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pPaAeXSeX4i",
        "outputId": "87c6d123-1b2d-4f48-c06e-eb0acb53985f"
      },
      "source": [
        "!conda install -c pytorch pytorch=1.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.5.4\n",
            "  latest version: 4.9.2\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - pytorch=1.7.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-10.1.243       |       h6bb024c_0       513.2 MB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    numpy-1.14.2               |   py36hdbf6ddf_0         4.0 MB\n",
            "    dataclasses-0.7            |           py36_0          31 KB\n",
            "    pip-20.3.3                 |   py36h06a4308_0         2.0 MB\n",
            "    setuptools-52.0.0          |   py36h06a4308_0         933 KB\n",
            "    sqlite-3.31.1              |       h7b6447c_0         2.0 MB\n",
            "    python-3.6.6               |       hc3d631a_0        29.4 MB\n",
            "    libuv-1.40.0               |       h7b6447c_0         933 KB\n",
            "    pytorch-1.7.0              |py3.6_cuda10.1.243_cudnn7.6.3_0       552.4 MB  pytorch\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    openssl-1.0.2u             |       h7b6447c_0         3.1 MB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    ca-certificates-2021.1.19  |       h06a4308_0         128 KB\n",
            "    typing_extensions-3.7.4.3  |     pyha847dfd_0          25 KB\n",
            "    readline-7.0               |       h7b6447c_5         392 KB\n",
            "    ninja-1.8.2                |   py36h6bb024c_1         1.3 MB\n",
            "    wheel-0.36.2               |     pyhd3eb1b0_0          31 KB\n",
            "    certifi-2020.12.5          |   py36h06a4308_0         144 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.10 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:     0.1-main                                     \n",
            "    blas:              1.0-mkl                                      \n",
            "    cudatoolkit:       10.1.243-h6bb024c_0                          \n",
            "    dataclasses:       0.7-py36_0                                   \n",
            "    libuv:             1.40.0-h7b6447c_0                            \n",
            "    ninja:             1.8.2-py36h6bb024c_1                         \n",
            "    pytorch:           1.7.0-py3.6_cuda10.1.243_cudnn7.6.3_0 pytorch\n",
            "    typing_extensions: 3.7.4.3-pyha847dfd_0                         \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:   2018.03.07-0                                  --> 2021.1.19-h06a4308_0    \n",
            "    certifi:           2018.4.16-py36_0                              --> 2020.12.5-py36h06a4308_0\n",
            "    libedit:           3.1.20170329-h6b74fdf_2                       --> 3.1.20181209-hc058e9b_0 \n",
            "    libgcc-ng:         7.2.0-hdf63c60_3                              --> 9.1.0-hdf63c60_0        \n",
            "    numpy:             1.14.0-py36h3dfced4_1                         --> 1.14.2-py36hdbf6ddf_0   \n",
            "    openssl:           1.0.2o-h20670df_0                             --> 1.0.2u-h7b6447c_0       \n",
            "    pip:               10.0.1-py36_0                                 --> 20.3.3-py36h06a4308_0   \n",
            "    python:            3.6.5-hc3d631a_2                              --> 3.6.6-hc3d631a_0        \n",
            "    readline:          7.0-ha6073c6_4                                --> 7.0-h7b6447c_5          \n",
            "    setuptools:        39.2.0-py36_0                                 --> 52.0.0-py36h06a4308_0   \n",
            "    sqlite:            3.23.1-he433501_0                             --> 3.31.1-h7b6447c_0       \n",
            "    tk:                8.6.7-hc745277_3                              --> 8.6.10-hbc83047_0       \n",
            "    wheel:             0.31.1-py36_0                                 --> 0.36.2-pyhd3eb1b0_0     \n",
            "    xz:                5.2.4-h14c3975_4                              --> 5.2.5-h7b6447c_0        \n",
            "    zlib:              1.2.11-ha838bed_2                             --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cudatoolkit-10.1.243 | 513.2 MB | : 100% 1.0/1 [01:50<00:00, 110.30s/it]               \n",
            "zlib-1.2.11          |  120 KB | : 100% 1.0/1 [00:00<00:00, 11.07it/s]\n",
            "numpy-1.14.2         |  4.0 MB | : 100% 1.0/1 [00:01<00:00,  1.59s/it]               \n",
            "dataclasses-0.7      |   31 KB | : 100% 1.0/1 [00:00<00:00,  5.49it/s]               \n",
            "pip-20.3.3           |  2.0 MB | : 100% 1.0/1 [00:00<00:00,  1.06it/s]               \n",
            "setuptools-52.0.0    |  933 KB | : 100% 1.0/1 [00:00<00:00,  2.26it/s]               \n",
            "sqlite-3.31.1        |  2.0 MB | : 100% 1.0/1 [00:00<00:00,  2.19it/s]               \n",
            "python-3.6.6         | 29.4 MB | : 100% 1.0/1 [00:07<00:00,  7.89s/it]               \n",
            "libuv-1.40.0         |  933 KB | : 100% 1.0/1 [00:00<00:00,  4.24it/s]              \n",
            "pytorch-1.7.0        | 552.4 MB | : 100% 1.0/1 [02:01<00:00, 121.36s/it]               \n",
            "_libgcc_mutex-0.1    |    3 KB | : 100% 1.0/1 [00:00<00:00, 23.29it/s]\n",
            "openssl-1.0.2u       |  3.1 MB | : 100% 1.0/1 [00:00<00:00,  1.20it/s]               \n",
            "libgcc-ng-9.1.0      |  8.1 MB | : 100% 1.0/1 [00:01<00:00,  1.85s/it]               \n",
            "blas-1.0             |    6 KB | : 100% 1.0/1 [00:00<00:00, 24.51it/s]\n",
            "ca-certificates-2021 |  128 KB | : 100% 1.0/1 [00:00<00:00, 18.53it/s]\n",
            "typing_extensions-3. |   25 KB | : 100% 1.0/1 [00:00<00:00, 21.48it/s]\n",
            "readline-7.0         |  392 KB | : 100% 1.0/1 [00:00<00:00,  6.00it/s]               \n",
            "ninja-1.8.2          |  1.3 MB | : 100% 1.0/1 [00:00<00:00,  1.53it/s]               \n",
            "wheel-0.36.2         |   31 KB | : 100% 1.0/1 [00:00<00:00, 12.73it/s]\n",
            "certifi-2020.12.5    |  144 KB | : 100% 1.0/1 [00:00<00:00, 15.57it/s]\n",
            "xz-5.2.5             |  438 KB | : 100% 1.0/1 [00:00<00:00,  5.82it/s]               \n",
            "tk-8.6.10            |  3.2 MB | : 100% 1.0/1 [00:00<00:00,  1.14it/s]               \n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bXQd28MfkN8",
        "outputId": "11a96980-3830-47d5-a5c2-09f642ac80aa"
      },
      "source": [
        "!conda install -c pytorch torchaudio\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - torchaudio\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    torchaudio-0.7.0           |             py36         9.8 MB  pytorch\n",
            "    conda-package-handling-1.7.2|   py36h03888b9_0         967 KB\n",
            "    matplotlib-2.2.2           |   py36hb69df0a_2         6.6 MB\n",
            "    fontconfig-2.13.1          |       h6c09931_0         299 KB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    pcre-8.44                  |       he6710b0_0         269 KB\n",
            "    libcurl-7.69.1             |       h20c2e04_0         591 KB\n",
            "    glib-2.63.1                |       h5a9c865_0         3.4 MB\n",
            "    kiwisolver-1.3.1           |   py36h2531618_0          86 KB\n",
            "    tqdm-4.56.0                |     pyhd3eb1b0_0          76 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         610 KB\n",
            "    openssl-1.1.1i             |       h27cfd23_0         3.8 MB\n",
            "    pycurl-7.43.0.5            |   py36h1ba5d50_0          71 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          16 KB\n",
            "    harfbuzz-1.8.8             |       hffaf4a1_0         863 KB\n",
            "    fribidi-1.0.10             |       h7b6447c_0         115 KB\n",
            "    cairo-1.14.12              |       h8948797_3         1.3 MB\n",
            "    cryptography-3.3.1         |   py36h3c74f83_0         638 KB\n",
            "    krb5-1.17.1                |       h173b8e3_0         1.5 MB\n",
            "    freetype-2.10.4            |       h5ab3b9f_0         901 KB\n",
            "    python-3.6.10              |       h0371630_0        33.9 MB\n",
            "    graphite2-1.3.14           |       h23475e2_0         102 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         364 KB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         645 KB\n",
            "    conda-4.9.2                |   py36h06a4308_0         3.1 MB\n",
            "    curl-7.69.1                |       hbc83047_0         148 KB\n",
            "    pango-1.42.4               |       h049681c_0         528 KB\n",
            "    libxml2-2.9.10             |       hb55368b_3         1.3 MB\n",
            "    libssh2-1.9.0              |       h1ba5d50_1         346 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        76.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    conda-package-handling: 1.7.2-py36h03888b9_0           \n",
            "    fribidi:                1.0.10-h7b6447c_0              \n",
            "    kiwisolver:             1.3.1-py36h2531618_0           \n",
            "    krb5:                   1.17.1-h173b8e3_0              \n",
            "    ld_impl_linux-64:       2.33.1-h53a641e_7              \n",
            "    libuuid:                1.0.3-h1bed415_2               \n",
            "    torchaudio:             0.7.0-py36              pytorch\n",
            "    tqdm:                   4.56.0-pyhd3eb1b0_0            \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    cairo:                  1.14.12-h77bcde2_0              --> 1.14.12-h8948797_3     \n",
            "    conda:                  4.5.4-py36_0                    --> 4.9.2-py36h06a4308_0   \n",
            "    cryptography:           2.2.2-py36h14c3975_0            --> 3.3.1-py36h3c74f83_0   \n",
            "    curl:                   7.58.0-h84994c4_0               --> 7.69.1-hbc83047_0      \n",
            "    dbus:                   1.12.2-hc3f9b76_1               --> 1.13.2-h714fa37_1      \n",
            "    fontconfig:             2.12.4-h88586e7_1               --> 2.13.1-h6c09931_0      \n",
            "    freetype:               2.8-hab7d2ae_1                  --> 2.10.4-h5ab3b9f_0      \n",
            "    glib:                   2.53.6-h5d9569c_2               --> 2.63.1-h5a9c865_0      \n",
            "    graphite2:              1.3.10-hf63cedd_1               --> 1.3.14-h23475e2_0      \n",
            "    gst-plugins-base:       1.12.4-h33fb286_0               --> 1.14.0-hbbd80ab_1      \n",
            "    gstreamer:              1.12.4-hb53b477_0               --> 1.14.0-hb453b48_1      \n",
            "    harfbuzz:               1.7.4-hc5b324e_0                --> 1.8.8-hffaf4a1_0       \n",
            "    libcurl:                7.58.0-h1ad7b7a_0               --> 7.69.1-h20c2e04_0      \n",
            "    libpng:                 1.6.34-hb9fc6fc_0               --> 1.6.37-hbc83047_0      \n",
            "    libssh2:                1.8.0-h9cfc8f7_4                --> 1.9.0-h1ba5d50_1       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3                --> 9.1.0-hdf63c60_0       \n",
            "    libxcb:                 1.12-hcd93eb1_4                 --> 1.14-h7b6447c_0        \n",
            "    libxml2:                2.9.7-h26e45fe_0                --> 2.9.10-hb55368b_3      \n",
            "    matplotlib:             2.1.2-py36h0e671d2_0            --> 2.2.2-py36hb69df0a_2   \n",
            "    openssl:                1.0.2u-h7b6447c_0               --> 1.1.1i-h27cfd23_0      \n",
            "    pango:                  1.41.0-hd475d92_0               --> 1.42.4-h049681c_0      \n",
            "    pcre:                   8.41-hc27e229_1                 --> 8.44-he6710b0_0        \n",
            "    pillow:                 5.0.0-py36h3deb7b8_0            --> 5.4.1-py36h34e0f95_0   \n",
            "    pycurl:                 7.43.0.1-py36hb7f436b_0         --> 7.43.0.5-py36h1ba5d50_0\n",
            "    python:                 3.6.6-hc3d631a_0                --> 3.6.10-h0371630_0      \n",
            "    qt:                     5.6.2-h974d657_12               --> 5.6.3-h8bf5577_3       \n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "torchaudio-0.7.0     |  9.8 MB | : 100% 1.0/1 [00:03<00:00,  3.44s/it]               \n",
            "conda-package-handli |  967 KB | : 100% 1.0/1 [00:00<00:00,  2.60it/s]               \n",
            "matplotlib-2.2.2     |  6.6 MB | : 100% 1.0/1 [00:02<00:00,  2.21s/it]               \n",
            "fontconfig-2.13.1    |  299 KB | : 100% 1.0/1 [00:00<00:00,  7.57it/s]               \n",
            "libstdcxx-ng-9.1.0   |  4.0 MB | : 100% 1.0/1 [00:00<00:00,  1.09it/s]               \n",
            "pcre-8.44            |  269 KB | : 100% 1.0/1 [00:00<00:00,  8.45it/s]              \n",
            "libcurl-7.69.1       |  591 KB | : 100% 1.0/1 [00:00<00:00,  4.98it/s]               \n",
            "glib-2.63.1          |  3.4 MB | : 100% 1.0/1 [00:01<00:00,  1.16s/it]              \n",
            "kiwisolver-1.3.1     |   86 KB | : 100% 1.0/1 [00:00<00:00, 16.73it/s]\n",
            "tqdm-4.56.0          |   76 KB | : 100% 1.0/1 [00:00<00:00, 13.42it/s]\n",
            "libxcb-1.14          |  610 KB | : 100% 1.0/1 [00:00<00:00,  3.05it/s]               \n",
            "openssl-1.1.1i       |  3.8 MB | : 100% 1.0/1 [00:00<00:00,  1.08it/s]               \n",
            "pycurl-7.43.0.5      |   71 KB | : 100% 1.0/1 [00:00<00:00, 19.39it/s]\n",
            "libuuid-1.0.3        |   16 KB | : 100% 1.0/1 [00:00<00:00, 19.17it/s]\n",
            "harfbuzz-1.8.8       |  863 KB | : 100% 1.0/1 [00:00<00:00,  4.45it/s]               \n",
            "fribidi-1.0.10       |  115 KB | : 100% 1.0/1 [00:00<00:00,  3.69it/s]                \n",
            "cairo-1.14.12        |  1.3 MB | : 100% 1.0/1 [00:00<00:00,  2.33it/s]               \n",
            "cryptography-3.3.1   |  638 KB | : 100% 1.0/1 [00:00<00:00,  3.03it/s]               \n",
            "krb5-1.17.1          |  1.5 MB | : 100% 1.0/1 [00:00<00:00,  2.34it/s]               \n",
            "freetype-2.10.4      |  901 KB | : 100% 1.0/1 [00:00<00:00,  2.57it/s]               \n",
            "python-3.6.10        | 33.9 MB | : 100% 1.0/1 [00:09<00:00,  9.95s/it]               \n",
            "graphite2-1.3.14     |  102 KB | : 100% 1.0/1 [00:00<00:00, 15.06it/s]\n",
            "libpng-1.6.37        |  364 KB | : 100% 1.0/1 [00:00<00:00,  7.84it/s]              \n",
            "ld_impl_linux-64-2.3 |  645 KB | : 100% 1.0/1 [00:00<00:00,  5.14it/s]               \n",
            "conda-4.9.2          |  3.1 MB | : 100% 1.0/1 [00:01<00:00,  1.00s/it]               \n",
            "curl-7.69.1          |  148 KB | : 100% 1.0/1 [00:00<00:00, 16.80it/s]\n",
            "pango-1.42.4         |  528 KB | : 100% 1.0/1 [00:00<00:00,  1.63it/s]               \n",
            "libxml2-2.9.10       |  1.3 MB | : 100% 1.0/1 [00:00<00:00,  1.73it/s]               \n",
            "libssh2-1.9.0        |  346 KB | : 100% 1.0/1 [00:00<00:00,  5.91it/s]               \n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PawAHbWAsrZO",
        "outputId": "96924dd7-7738-4b4f-c3bc-aea97d240418"
      },
      "source": [
        "!bash audio_traineval.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training got interrupted, saving log-files now.\n",
            "Saving model and log-file to ./logs/audio_experiment\n",
            "not enough models there yet, nothing to delete\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltkBHcq8SxL7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import os.path\n",
        "import torchaudio\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0siCm4FjLJD"
      },
      "source": [
        "# CPC model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfa0HGEaIU-l"
      },
      "source": [
        "The class for the actual model with 3 different types.\n",
        "\n",
        "1. The CPC model according to Oord et al.\n",
        "2. GIM model, where the last encoding layer is trained together with the autoregressor\n",
        "3. GIM model in which the last autoregressive layer is trained independently"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQzhPRhmMm1s"
      },
      "source": [
        "class FullModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        opt,\n",
        "        kernel_sizes,\n",
        "        strides,\n",
        "        padding,\n",
        "        enc_hidden,\n",
        "        reg_hidden,\n",
        "        calc_accuracy=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Entire CPC model that can be split into smaller chunks for training\n",
        "        \"\"\"\n",
        "        super(FullModel, self).__init__()\n",
        "\n",
        "        self.opt = opt\n",
        "        self.reg_hidden = reg_hidden\n",
        "        self.enc_hidden = enc_hidden\n",
        "\n",
        "        # load model\n",
        "        self.fullmodel = nn.ModuleList([])\n",
        "\n",
        "        if self.opt.model_splits == 1:\n",
        "            # CPC model\n",
        "            self.fullmodel.append(\n",
        "                independent_module.IndependentModule(\n",
        "                    opt,\n",
        "                    enc_kernel_sizes=kernel_sizes,\n",
        "                    enc_strides=strides,\n",
        "                    enc_padding=padding,\n",
        "                    enc_hidden=enc_hidden,\n",
        "                    reg_hidden=reg_hidden,\n",
        "                    calc_accuracy=calc_accuracy,\n",
        "                )\n",
        "            )\n",
        "        elif self.opt.model_splits == 5:\n",
        "            # GIM model, where the last encoding layer is trained together with the autoregressor\n",
        "            enc_input = 1\n",
        "            last_idx = len(kernel_sizes) - 1\n",
        "\n",
        "            for i in range(last_idx):\n",
        "                self.fullmodel.append(\n",
        "                    independent_module.IndependentModule(\n",
        "                        opt,\n",
        "                        enc_input=enc_input,\n",
        "                        enc_kernel_sizes=[kernel_sizes[i]],\n",
        "                        enc_strides=[strides[i]],\n",
        "                        enc_padding=[padding[i]],\n",
        "                        enc_hidden=enc_hidden,\n",
        "                        reg_hidden=reg_hidden,\n",
        "                        use_autoregressive=self.opt.use_autoregressive,\n",
        "                        calc_accuracy=calc_accuracy,\n",
        "                    )\n",
        "                )\n",
        "                enc_input = enc_hidden\n",
        "\n",
        "            self.fullmodel.append(\n",
        "                independent_module.IndependentModule(\n",
        "                    opt,\n",
        "                    enc_input=enc_input,\n",
        "                    enc_kernel_sizes=[kernel_sizes[last_idx]],\n",
        "                    enc_strides=[strides[last_idx]],\n",
        "                    enc_padding=[padding[last_idx]],\n",
        "                    enc_hidden=enc_hidden,\n",
        "                    reg_hidden=reg_hidden,\n",
        "                    use_autoregressive=True,\n",
        "                    calc_accuracy=calc_accuracy,\n",
        "                )\n",
        "            )\n",
        "        elif (\n",
        "            self.opt.model_splits == 6\n",
        "        ):  # GIM model in which the last autoregressive layer is trained independently\n",
        "            enc_input = 1\n",
        "\n",
        "            for i in range(len(kernel_sizes)):\n",
        "                self.fullmodel.append(\n",
        "                    independent_module.IndependentModule(\n",
        "                        opt,\n",
        "                        enc_input=enc_input,\n",
        "                        enc_kernel_sizes=[kernel_sizes[i]],\n",
        "                        enc_strides=[strides[i]],\n",
        "                        enc_padding=[padding[i]],\n",
        "                        enc_hidden=enc_hidden,\n",
        "                        reg_hidden=reg_hidden,\n",
        "                        use_autoregressive=self.opt.use_autoregressive,\n",
        "                        calc_accuracy=calc_accuracy,\n",
        "                    )\n",
        "                )\n",
        "                enc_input = enc_hidden\n",
        "\n",
        "            if not self.opt.use_autoregressive:\n",
        "                # append separate autoregressive layer\n",
        "                self.fullmodel.append(\n",
        "                    independent_module.IndependentModule(\n",
        "                        opt,\n",
        "                        enc_input=enc_input,\n",
        "                        enc_hidden=enc_hidden,\n",
        "                        reg_hidden=reg_hidden,\n",
        "                        use_encoder=False,\n",
        "                        enc_kernel_sizes=None,\n",
        "                        enc_strides=None,\n",
        "                        enc_padding=None,\n",
        "                        use_autoregressive=True,\n",
        "                        calc_accuracy=calc_accuracy,\n",
        "                    )\n",
        "                )\n",
        "        else:\n",
        "            raise Exception(\"Invalid option for opt.model_splits\")\n",
        "\n",
        "    def forward(self, x, filename=None, start_idx=None, n=6):\n",
        "        model_input = x\n",
        "\n",
        "        cur_device = utils.get_device(self.opt, x)\n",
        "\n",
        "        # first dimension is used for concatenating results from different GPUs\n",
        "        loss = torch.zeros(1, len(self.fullmodel), device=cur_device)\n",
        "        accuracy = torch.zeros(1, len(self.fullmodel), device=cur_device)\n",
        "\n",
        "        if n == 6:  # train all layers at once\n",
        "            for idx, layer in enumerate(self.fullmodel):\n",
        "                loss[:, idx], accuracy[:, idx], _, z = layer(\n",
        "                    model_input, filename, start_idx\n",
        "                )\n",
        "                model_input = z.permute(0, 2, 1).detach()\n",
        "        else:\n",
        "            \"\"\"\n",
        "            forward to the layer that we want to train and only output that layer's loss\n",
        "            (all other values stay at zero initialization)\n",
        "            This does not reap the memory benefits that would be possible if we trained layers completely separately \n",
        "            (by training a layer and saving its output as the dataset to train the next layer on), but enables us \n",
        "            to test the behaviour of the model for greedy iterative training\n",
        "            \"\"\"\n",
        "            assert (\n",
        "                self.opt.model_splits == 5 or self.opt.model_splits == 6\n",
        "            ), \"Works only for GIM model training\"\n",
        "\n",
        "            for idx, layer in enumerate(self.fullmodel[: n + 1]):\n",
        "                if idx == n:\n",
        "                    loss[:, idx], accuracy[:, idx], _, _ = layer(\n",
        "                        model_input, filename, start_idx\n",
        "                    )\n",
        "                else:\n",
        "                    _, z = layer.get_latents(model_input)\n",
        "                    model_input = z.permute(0, 2, 1).detach()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward_through_n_layers(self, x, n):\n",
        "        if self.opt.model_splits == 1:\n",
        "            if n > 4:\n",
        "                model_input = x\n",
        "                for idx, layer in enumerate(self.fullmodel):\n",
        "                    c, z = layer.get_latents(model_input)\n",
        "                    model_input = z.permute(0, 2, 1).detach()\n",
        "                x = c\n",
        "            else:\n",
        "                x = self.fullmodel[0].encoder.forward_through_n_layers(\n",
        "                    x, n+1\n",
        "                )\n",
        "                x = x.permute(0, 2, 1)\n",
        "        elif self.opt.model_splits == 6 or self.opt.model_splits == 5:\n",
        "            model_input = x\n",
        "            for idx, layer in enumerate(self.fullmodel[: n + 1]):\n",
        "                c, z = layer.get_latents(model_input)\n",
        "                model_input = z.permute(0, 2, 1).detach()\n",
        "            if n < 5:\n",
        "                x = z\n",
        "            else:\n",
        "                x = c\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6qSMFs5jP7e"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnHSBGPaTObG"
      },
      "source": [
        "Utilities for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve3zEr_BTPzC"
      },
      "source": [
        "def distribute_over_GPUs(opt, model, num_GPU):\n",
        "    ## distribute over GPUs\n",
        "    if opt.device.type != \"cpu\":\n",
        "        if num_GPU is None:\n",
        "            model = nn.DataParallel(model)\n",
        "            num_GPU = torch.cuda.device_count()\n",
        "            opt.batch_size_multiGPU = opt.batch_size * num_GPU\n",
        "        else:\n",
        "            assert (\n",
        "                num_GPU <= torch.cuda.device_count()\n",
        "            ), \"You cant use more GPUs than you have.\"\n",
        "            model = nn.DataParallel(model, device_ids=list(range(num_GPU)))\n",
        "            opt.batch_size_multiGPU = opt.batch_size * num_GPU\n",
        "    else:\n",
        "        model = nn.DataParallel(model)\n",
        "        opt.batch_size_multiGPU = opt.batch_size\n",
        "\n",
        "    model = model.to(opt.device)\n",
        "    print(\"Let's use\", num_GPU, \"GPUs!\")\n",
        "\n",
        "    return model, num_GPU\n",
        "\n",
        "\n",
        "def genOrthgonal(dim):\n",
        "    a = torch.zeros((dim, dim)).normal_(0, 1)\n",
        "    q, r = torch.qr(a)\n",
        "    d = torch.diag(r, 0).sign()\n",
        "    diag_size = d.size(0)\n",
        "    d_exp = d.view(1, diag_size).expand(diag_size, diag_size)\n",
        "    q.mul_(d_exp)\n",
        "    return q\n",
        "\n",
        "\n",
        "def makeDeltaOrthogonal(weights, gain):\n",
        "    rows = weights.size(0)\n",
        "    cols = weights.size(1)\n",
        "    if rows > cols:\n",
        "        print(\"In_filters should not be greater than out_filters.\")\n",
        "    weights.data.fill_(0)\n",
        "    dim = max(rows, cols)\n",
        "    q = genOrthgonal(dim)\n",
        "    mid1 = weights.size(2) // 2\n",
        "    mid2 = weights.size(3) // 2\n",
        "    with torch.no_grad():\n",
        "        weights[:, :, mid1, mid2] = q[: weights.size(0), : weights.size(1)]\n",
        "        weights.mul_(gain)\n",
        "\n",
        "\n",
        "def reload_weights(opt, model, optimizer, reload_model):\n",
        "    ## reload weights for training of the linear classifier\n",
        "    if (opt.model_type == 0) and reload_model:  # or opt.model_type == 2)\n",
        "        print(\"Loading weights from \", opt.model_path)\n",
        "\n",
        "        if opt.experiment == \"audio\":\n",
        "            model.load_state_dict(\n",
        "                torch.load(\n",
        "                    os.path.join(opt.model_path, \"model_{}.ckpt\".format(opt.model_num)),\n",
        "                    map_location=opt.device.type,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            for idx, layer in enumerate(model.module.encoder):\n",
        "                model.module.encoder[idx].load_state_dict(\n",
        "                    torch.load(\n",
        "                        os.path.join(\n",
        "                            opt.model_path,\n",
        "                            \"model_{}_{}.ckpt\".format(idx, opt.model_num),\n",
        "                        ),\n",
        "                         map_location=opt.device.type,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    ## reload weights and optimizers for continuing training\n",
        "    elif opt.start_epoch > 0:\n",
        "        print(\"Continuing training from epoch \", opt.start_epoch)\n",
        "\n",
        "        if opt.experiment == \"audio\":\n",
        "            model.load_state_dict(\n",
        "                torch.load(\n",
        "                    os.path.join(\n",
        "                        opt.model_path, \"model_{}.ckpt\".format(opt.start_epoch)\n",
        "                    ),\n",
        "                    map_location=opt.device.type,\n",
        "                ),\n",
        "                strict=False,\n",
        "            )\n",
        "        else:\n",
        "            for idx, layer in enumerate(model.module.encoder):\n",
        "                model.module.encoder[idx].load_state_dict(\n",
        "                    torch.load(\n",
        "                        os.path.join(\n",
        "                            opt.model_path,\n",
        "                            \"model_{}_{}.ckpt\".format(idx, opt.start_epoch),\n",
        "                        ),\n",
        "                        map_location=opt.device.type,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        for i, optim in enumerate(optimizer):\n",
        "            if opt.model_splits > 3 and i > 2:\n",
        "                break\n",
        "            optim.load_state_dict(\n",
        "                torch.load(\n",
        "                    os.path.join(\n",
        "                        opt.model_path,\n",
        "                        \"optim_{}_{}.ckpt\".format(str(i), opt.start_epoch),\n",
        "                    ),\n",
        "                    map_location=opt.device.type,\n",
        "                )\n",
        "            )\n",
        "    else:\n",
        "        print(\"Randomly initialized model\")\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQauT0k1jUKb"
      },
      "source": [
        "# Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4kg90YmjBas"
      },
      "source": [
        "Class for logger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h-f6canjC4C"
      },
      "source": [
        "class Logger:\n",
        "    def __init__(self, opt):\n",
        "        self.opt = opt\n",
        "\n",
        "        if opt.validate:\n",
        "            self.val_loss = [[] for i in range(opt.model_splits)]\n",
        "        else:\n",
        "            self.val_loss = None\n",
        "\n",
        "        self.train_loss = [[] for i in range(opt.model_splits)]\n",
        "\n",
        "        if opt.start_epoch > 0:\n",
        "            self.loss_last_training = np.load(\n",
        "                os.path.join(opt.model_path, \"train_loss.npy\")\n",
        "            ).tolist()\n",
        "            self.train_loss[:len(self.loss_last_training)] = copy.deepcopy(self.loss_last_training)\n",
        "\n",
        "\n",
        "            if opt.validate:\n",
        "                self.val_loss_last_training = np.load(\n",
        "                    os.path.join(opt.model_path, \"val_loss.npy\")\n",
        "                ).tolist()\n",
        "                self.val_loss[:len(self.val_loss_last_training)] = copy.deepcopy(self.val_loss_last_training)\n",
        "            else:\n",
        "                self.val_loss = None\n",
        "        else:\n",
        "            self.loss_last_training = None\n",
        "\n",
        "            if opt.validate:\n",
        "                self.val_loss = [[] for i in range(opt.model_splits)]\n",
        "            else:\n",
        "                self.val_loss = None\n",
        "\n",
        "        self.num_models_to_keep = 1\n",
        "        assert self.num_models_to_keep > 0, \"Dont delete all models!!!\"\n",
        "\n",
        "    def create_log(\n",
        "        self,\n",
        "        model,\n",
        "        accuracy=None,\n",
        "        epoch=0,\n",
        "        optimizer=None,\n",
        "        final_test=False,\n",
        "        final_loss=None,\n",
        "        acc5=None,\n",
        "        classification_model=None\n",
        "    ):\n",
        "\n",
        "        print(\"Saving model and log-file to \" + self.opt.log_path)\n",
        "\n",
        "        # Save the model checkpoint\n",
        "        if self.opt.experiment == \"vision\":\n",
        "            for idx, layer in enumerate(model.module.encoder):\n",
        "                torch.save(\n",
        "                    layer.state_dict(),\n",
        "                    os.path.join(self.opt.log_path, \"model_{}_{}.ckpt\".format(idx, epoch)),\n",
        "                )\n",
        "        else:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(self.opt.log_path, \"model_{}.ckpt\".format(epoch)),\n",
        "            )\n",
        "\n",
        "        ### remove old model files to keep dir uncluttered\n",
        "        if (epoch - self.num_models_to_keep) % 10 != 0:\n",
        "            try:\n",
        "                if self.opt.experiment == \"vision\":\n",
        "                    for idx, _ in enumerate(model.module.encoder):\n",
        "                        os.remove(\n",
        "                            os.path.join(\n",
        "                                self.opt.log_path,\n",
        "                                \"model_{}_{}.ckpt\".format(idx, epoch - self.num_models_to_keep),\n",
        "                            )\n",
        "                        )\n",
        "                else:\n",
        "                    os.remove(\n",
        "                        os.path.join(\n",
        "                            self.opt.log_path,\n",
        "                            \"model_{}.ckpt\".format(epoch - self.num_models_to_keep),\n",
        "                        )\n",
        "                    )\n",
        "            except:\n",
        "                print(\"not enough models there yet, nothing to delete\")\n",
        "\n",
        "\n",
        "        if classification_model is not None:\n",
        "            # Save the predict model checkpoint\n",
        "            torch.save(\n",
        "                classification_model.state_dict(),\n",
        "                os.path.join(self.opt.log_path, \"classification_model_{}.ckpt\".format(epoch)),\n",
        "            )\n",
        "\n",
        "            ### remove old model files to keep dir uncluttered\n",
        "            try:\n",
        "                os.remove(\n",
        "                    os.path.join(\n",
        "                        self.opt.log_path,\n",
        "                        \"classification_model_{}.ckpt\".format(epoch - self.num_models_to_keep),\n",
        "                    )\n",
        "                )\n",
        "            except:\n",
        "                print(\"not enough models there yet, nothing to delete\")\n",
        "\n",
        "        if optimizer is not None:\n",
        "            for idx, optims in enumerate(optimizer):\n",
        "                torch.save(\n",
        "                    optims.state_dict(),\n",
        "                    os.path.join(\n",
        "                        self.opt.log_path, \"optim_{}_{}.ckpt\".format(idx, epoch)\n",
        "                    ),\n",
        "                )\n",
        "\n",
        "                try:\n",
        "                    os.remove(\n",
        "                        os.path.join(\n",
        "                            self.opt.log_path,\n",
        "                            \"optim_{}_{}.ckpt\".format(\n",
        "                                idx, epoch - self.num_models_to_keep\n",
        "                            ),\n",
        "                        )\n",
        "                    )\n",
        "                except:\n",
        "                    print(\"not enough models there yet, nothing to delete\")\n",
        "\n",
        "        # Save hyper-parameters\n",
        "        with open(os.path.join(self.opt.log_path, \"log.txt\"), \"w+\") as cur_file:\n",
        "            cur_file.write(str(self.opt))\n",
        "            if accuracy is not None:\n",
        "                cur_file.write(\"Top 1 -  accuracy: \" + str(accuracy))\n",
        "            if acc5 is not None:\n",
        "                cur_file.write(\"Top 5 - Accuracy: \" + str(acc5))\n",
        "            if final_test and accuracy is not None:\n",
        "                cur_file.write(\" Very Final testing accuracy: \" + str(accuracy))\n",
        "            if final_test and acc5 is not None:\n",
        "                cur_file.write(\" Very Final testing top 5 - accuracy: \" + str(acc5))\n",
        "\n",
        "        # Save losses throughout training and plot\n",
        "        np.save(\n",
        "            os.path.join(self.opt.log_path, \"train_loss\"), np.array(self.train_loss)\n",
        "        )\n",
        "\n",
        "        if self.val_loss is not None:\n",
        "            np.save(\n",
        "                os.path.join(self.opt.log_path, \"val_loss\"), np.array(self.val_loss)\n",
        "            )\n",
        "\n",
        "        self.draw_loss_curve()\n",
        "\n",
        "        if accuracy is not None:\n",
        "            np.save(os.path.join(self.opt.log_path, \"accuracy\"), accuracy)\n",
        "\n",
        "        if final_test:\n",
        "            np.save(os.path.join(self.opt.log_path, \"final_accuracy\"), accuracy)\n",
        "            np.save(os.path.join(self.opt.log_path, \"final_loss\"), final_loss)\n",
        "\n",
        "\n",
        "    def draw_loss_curve(self):\n",
        "        for idx, loss in enumerate(self.train_loss):\n",
        "            lst_iter = np.arange(len(loss))\n",
        "            plt.plot(lst_iter, np.array(loss), \"-b\", label=\"train loss\")\n",
        "\n",
        "            if self.loss_last_training is not None and len(self.loss_last_training) > idx:\n",
        "                lst_iter = np.arange(len(self.loss_last_training[idx]))\n",
        "                plt.plot(lst_iter, self.loss_last_training[idx], \"-g\")\n",
        "\n",
        "            if self.val_loss is not None and len(self.val_loss) > idx:\n",
        "                lst_iter = np.arange(len(self.val_loss[idx]))\n",
        "                plt.plot(lst_iter, np.array(self.val_loss[idx]), \"-r\", label=\"val loss\")\n",
        "\n",
        "            plt.xlabel(\"epoch\")\n",
        "            plt.ylabel(\"loss\")\n",
        "            plt.legend(loc=\"upper right\")\n",
        "            # plt.axis([0, max(200,len(loss)+self.opt.start_epoch), 0, -round(np.log(1/(self.opt.negative_samples+1)),1)])\n",
        "\n",
        "            # save image\n",
        "            plt.savefig(os.path.join(self.opt.log_path, \"loss_{}.png\".format(idx)))\n",
        "            plt.close()\n",
        "\n",
        "    def append_train_loss(self, train_loss):\n",
        "        for idx, elem in enumerate(train_loss):\n",
        "            self.train_loss[idx].append(elem)\n",
        "\n",
        "    def append_val_loss(self, val_loss):\n",
        "        for idx, elem in enumerate(val_loss):\n",
        "            self.val_loss[idx].append(elem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91s23c6pjcUI"
      },
      "source": [
        "# Load model and optimiser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKLsRRjOIXgd"
      },
      "source": [
        "This function initialises the model with dimensions given in the Oord et al paper, although padding was not mentioned.\n",
        "\n",
        "This function also makes sure only one GPU is used for when we're doign supervised loss.\n",
        "\n",
        "The function also initialises the ADAM optimiser.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdEAtdk-KO5G"
      },
      "source": [
        "def load_model_and_optimizer(\n",
        "    opt, reload_model=False, calc_accuracy=False, num_GPU=None\n",
        "):\n",
        "\n",
        "    # original dimensions given in CPC paper (Oord et al.)\n",
        "    kernel_sizes = [10, 8, 4, 4, 4]\n",
        "    strides = [5, 4, 2, 2, 2]\n",
        "    padding = [2, 2, 2, 2, 1]\n",
        "    enc_hidden = 512\n",
        "    reg_hidden = 256\n",
        "\n",
        "    ## initialize model\n",
        "    model = full_model.FullModel(\n",
        "        opt,\n",
        "        kernel_sizes=kernel_sizes,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        enc_hidden=enc_hidden,\n",
        "        reg_hidden=reg_hidden,\n",
        "        calc_accuracy=calc_accuracy,\n",
        "    )\n",
        "\n",
        "    # run on only one GPU for supervised losses\n",
        "    if opt.loss == 2 or opt.loss == 1:\n",
        "        num_GPU = 1\n",
        "\n",
        "    model, num_GPU = model_utils.distribute_over_GPUs(opt, model, num_GPU=num_GPU)\n",
        "\n",
        "    \"\"\" initialize optimizers\n",
        "    We need to have a separate optimizer for every individually trained part of the network\n",
        "    as calling optimizer.step() would otherwise cause all parts of the network to be updated\n",
        "    even when their respective gradients are zero (due to momentum)\n",
        "    \"\"\"\n",
        "    optimizer = []\n",
        "    for idx, layer in enumerate(model.module.fullmodel):\n",
        "        if isinstance(opt.learning_rate, list):\n",
        "            cur_lr = opt.learning_rate[idx]\n",
        "        else:\n",
        "            cur_lr = opt.learning_rate\n",
        "        optimizer.append(torch.optim.Adam(layer.parameters(), lr=cur_lr))\n",
        "\n",
        "    model, optimizer = model_utils.reload_weights(opt, model, optimizer, reload_model)\n",
        "\n",
        "    model.train()\n",
        "    print(model)\n",
        "\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smHul9-yjj3W"
      },
      "source": [
        "# Get datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COYLFR60xSE3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}